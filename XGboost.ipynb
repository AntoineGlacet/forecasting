{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "data_origin = pd.read_csv(\n",
    "    \"/home/antoine/projects/forecasting/data/KIX_AODB_data.csv\",\n",
    "    low_memory=False,\n",
    ")\n",
    "data_airports = pd.read_csv(\n",
    "    \"/home/antoine/projects/forecasting/data/AODB_airport_master.csv\"\n",
    ")\n",
    "\n",
    "data_countries = pd.read_csv(\n",
    "    \"/home/antoine/projects/forecasting/data/AODB_country_master.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "all_files = list(Path(\"/home/antoine/projects/forecasting/data/planned flights\").glob('*.csv'))\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11730/306127209.py:49: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  .T.to_dict(orient=\"records\")\n"
     ]
    }
   ],
   "source": [
    "# select only useful columns\n",
    "data = data_origin[\n",
    "    [\n",
    "        \"Service Type\",  # string\n",
    "        \"Traffic Type\",  # string\n",
    "        \"Capacity\",  # to convert to int\n",
    "        \"L Board Pax\",  # int already\n",
    "        \"Direction\",  # string\n",
    "        \"Date\",  # date to convert to int for year/month/date\n",
    "        \"time\",  # time to convert to int for hour\n",
    "        \"Routing-FirstLeg\",  # string, should be country\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# filter out rows with irrelevant values\n",
    "mask = (\n",
    "    (data[\"Service Type\"].isin([\"C\", \"G\", \"J\"]))\n",
    "    & (data[\"Capacity\"] != 0)\n",
    "    & (data[\"L Board Pax\"] != 0)\n",
    ")\n",
    "data = data[mask].copy()\n",
    "\n",
    "# change capacity to numerical\n",
    "data[\"Capacity\"] = pd.to_numeric(data[\"Capacity\"], errors=\"coerce\")\n",
    "\n",
    "# split date into year month day\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "data[\"Year\"] = data[\"Date\"].apply(lambda x: x.year)\n",
    "data[\"Month\"] = data[\"Date\"].apply(lambda x: x.month)\n",
    "data[\"Day\"] = data[\"Date\"].apply(lambda x: x.day)\n",
    "\n",
    "# change time to number of hour (int)\n",
    "data[\"Hour\"] = pd.to_datetime(data[\"time\"]).apply(lambda x: x.hour)\n",
    "\n",
    "# drop na and convert to int\n",
    "data.dropna(inplace=True)\n",
    "data[\"Capacity\"] = data[\"Capacity\"].astype(\"int\")\n",
    "data[\"L Board Pax\"] = data[\"L Board Pax\"].astype(\"int\")\n",
    "\n",
    "# replace capacity and pax with Load Factor\n",
    "data[\"Load Factor\"] = data[\"L Board Pax\"] / data[\"Capacity\"]\n",
    "\n",
    "# change routing to Country name then to Country code\n",
    "repl = data_airports[[\"ICAO\", \"Country\"]].set_index(\"ICAO\").T.to_dict(orient=\"records\")\n",
    "data[\"Country\"] = data[\"Routing-FirstLeg\"].map(*repl)\n",
    "repl_country = (\n",
    "    data_countries[[\"Name\", \"ISO-3166-1 alpha-2\"]]\n",
    "    .set_index(\"Name\")\n",
    "    .T.to_dict(orient=\"records\")\n",
    ")\n",
    "data[\"Country\"] = data[\"Country\"].map(*repl_country)\n",
    "\n",
    "# holidays\n",
    "data[\"HolidayJP\"] = 0\n",
    "data[\"HolidayOrigin\"] = 0\n",
    "\n",
    "dct_holiday = {\n",
    "    country_code: holidays.country_holidays(country_code)\n",
    "    for country_code in data[\"Country\"].unique()\n",
    "    if hasattr(holidays, country_code)\n",
    "}\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    # domestic holiday\n",
    "    if row[\"Date\"] in dct_holiday[\"JP\"]:\n",
    "        data.loc[index, \"HolidayJP\"] = 1\n",
    "    # overseas holiday\n",
    "    if row[\"Country\"] in dct_holiday.keys():\n",
    "        if row[\"Date\"] in dct_holiday[row[\"Country\"]]:\n",
    "            data.loc[index, \"HolidayOrigin\"] = 1\n",
    "\n",
    "# drop old columns\n",
    "data.drop([\"L Board Pax\", \"Capacity\"], axis=\"columns\", inplace=True)\n",
    "data.drop(\"Routing-FirstLeg\", axis=\"columns\", inplace=True)\n",
    "data.drop(\"Date\", axis=\"columns\", inplace=True)\n",
    "data.drop(\"time\", axis=\"columns\", inplace=True)\n",
    "\n",
    "# change types for categories\n",
    "data[\"Service Type\"] = data[\"Service Type\"].astype(\"category\")\n",
    "data[\"Traffic Type\"] = data[\"Traffic Type\"].astype(\"category\")\n",
    "data[\"Direction\"] = data[\"Direction\"].astype(\"category\")\n",
    "data[\"Country\"] = data[\"Country\"].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline creation and first fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "X = data.drop(\"Load Factor\", axis=1)\n",
    "y = data[\"Load Factor\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)\n",
    "\n",
    "# pipeline creation\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "model = XGBRegressor()\n",
    "regressor = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"regressor\", XGBRegressor())]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.979\n",
      "model score: 0.534\n"
     ]
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train)\n",
    "print(\"training score: %.3f\" % regressor.score(X_train, y_train))\n",
    "print(\"model score: %.3f\" % regressor.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor[\"regressor\"].get_booster().feature_names = list(\n",
    "#     regressor[\"preprocessor\"].get_feature_names_out()\n",
    "# )\n",
    "# xgb.plot_importance(regressor[\"regressor\"], ax=plt.gca())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "hyperparameter_grid = {\n",
    "    'regressor__n_estimators': [100, 400, 800],\n",
    "    'regressor__max_depth': [3, 6, 9],\n",
    "    'regressor__learning_rate': [0.05, 0.1, 0.20],\n",
    "    'regressor__min_child_weight': [1, 10, 100]\n",
    "    }\n",
    "\n",
    "gridCV = GridSearchCV(regressor, param_grid = hyperparameter_grid,cv=4)\n",
    "gridCV.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print( gridCV.best_params_)\n",
    "print(\"Best score found on development set:\")\n",
    "print( gridCV.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on future schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to make predictions on future flights\n",
    "# plot total departure/arrival international/domestic pax for NOV=>JAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5cde2381dd949eede0613f4452aac5627aca93dd18e02f051004af15b34586f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
