{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_airports = pd.read_csv(\n",
    "    \"/home/antoine/projects/forecasting/data/AODB_airport_master.csv\"\n",
    ")\n",
    "\n",
    "data_countries = pd.read_csv(\n",
    "    \"/home/antoine/projects/forecasting/data/AODB_country_master.csv\"\n",
    ")\n",
    "\n",
    "all_files = list(\n",
    "    Path(\"/home/antoine/projects/forecasting/data/planned flights\").glob(\"*.csv\")\n",
    ")\n",
    "data_planned = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "\n",
    "all_files = list(\n",
    "    Path(\"/home/antoine/projects/forecasting/data/KIX_AODB_data\").glob(\"*.csv\")\n",
    ")\n",
    "data_actual = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "# filter out 17 January, it's today\n",
    "mask = pd.to_datetime(data_actual[\"[Arr] SIBT\"]).dt.floor(\"d\") != pd.to_datetime(\n",
    "    \"2023-1-17\"\n",
    ").floor(\"d\")\n",
    "data_actual = data_actual[mask].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning & augmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data_actual, training: bool = True):\n",
    "    # generate proper format\n",
    "    mask = data_actual[\"[Dep] Flight Designator\"].notna()\n",
    "    data_dep = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"L Board Pax\": pd.to_numeric(\n",
    "                data_actual[mask][\"[Dep]  L Board Pax\"], errors=\"coerce\"\n",
    "            ).to_list(),\n",
    "            \"Routing-FirstLeg\": data_actual[mask][\"[Dep] Routing\"]\n",
    "            .apply(lambda x: x[-4:])\n",
    "            .to_list(),\n",
    "            \"Datetime\": pd.to_datetime(data_actual[mask][\"[Dep] SOBT\"]).to_list(),\n",
    "            \"Service Type\": data_actual[mask][\"[Dep] Service Type\"].to_list(),\n",
    "            \"Traffic Type\": data_actual[mask][\"[Dep] Traffic Type\"].to_list(),\n",
    "            \"UniqueID\": pd.to_datetime(data_actual[mask][\"[Dep] SOBT\"]).dt.strftime(\n",
    "                \"%Y/%m/%d\"\n",
    "            )\n",
    "            + \" \"\n",
    "            + data_actual[mask][\"[Dep] Flight Designator\"],\n",
    "            \"Capacity\": pd.to_numeric(\n",
    "                data_actual[mask][\"[Dep] Capacity\"], errors=\"coerce\"\n",
    "            ).to_list(),\n",
    "            \"Flight Designator\": data_actual[mask][\"[Dep] Flight Designator\"],\n",
    "        }\n",
    "    )\n",
    "    data_dep[\"Direction\"] = \"departure\"\n",
    "\n",
    "    mask = data_actual[\"[Arr] Flight Designator\"].notna()\n",
    "    data_arr = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"L Board Pax\": pd.to_numeric(\n",
    "                data_actual[mask][\"[Arr]  L Board Pax\"], errors=\"coerce\"\n",
    "            ).to_list(),\n",
    "            \"Routing-FirstLeg\": data_actual[mask][\"[Arr] Routing\"]\n",
    "            .apply(lambda x: x[0:4])\n",
    "            .to_list(),\n",
    "            \"Datetime\": pd.to_datetime(data_actual[mask][\"[Arr] SIBT\"]).to_list(),\n",
    "            \"Service Type\": data_actual[mask][\"[Arr] Service Type\"].to_list(),\n",
    "            \"Traffic Type\": data_actual[mask][\"[Arr] Traffic Type\"].to_list(),\n",
    "            \"UniqueID\": pd.to_datetime(data_actual[mask][\"[Arr] SIBT\"]).dt.strftime(\n",
    "                \"%Y/%m/%d\"\n",
    "            )\n",
    "            + \" \"\n",
    "            + data_actual[mask][\"[Arr] Flight Designator\"],\n",
    "            \"Capacity\": pd.to_numeric(\n",
    "                data_actual[mask][\"[Arr] Capacity\"], errors=\"coerce\"\n",
    "            ).to_list(),\n",
    "            \"Flight Designator\": data_actual[mask][\"[Arr] Flight Designator\"],\n",
    "        }\n",
    "    )\n",
    "    data_arr[\"Direction\"] = \"arrival\"\n",
    "\n",
    "    data_concat = pd.concat([data_dep, data_arr]).reset_index(drop=True)\n",
    "    data_concat.drop_duplicates(subset=[\"UniqueID\"], inplace=True)\n",
    "    data = data_concat.copy()\n",
    "\n",
    "    # select only useful columns\n",
    "    data = data[\n",
    "        [\n",
    "            \"Service Type\",  # string\n",
    "            \"Traffic Type\",  # string\n",
    "            \"Capacity\",  # to convert to int\n",
    "            \"L Board Pax\",  # int already\n",
    "            \"Direction\",  # string\n",
    "            \"Datetime\",  # date to convert to int for year/month/date/hour\n",
    "            \"Routing-FirstLeg\",  # string, should be country\n",
    "            \"UniqueID\",\n",
    "            \"Flight Designator\",\n",
    "        ]\n",
    "    ].copy()\n",
    "\n",
    "    # filter out rows with irrelevant values\n",
    "    mask = data[\"Service Type\"].isin([\"C\", \"G\", \"J\"])\n",
    "    data = data[mask].copy()\n",
    "\n",
    "    # change capacity to numerical\n",
    "    data[\"Capacity\"] = pd.to_numeric(data[\"Capacity\"], errors=\"coerce\")\n",
    "    data[\"L Board Pax\"] = pd.to_numeric(data[\"L Board Pax\"], errors=\"coerce\")\n",
    "\n",
    "    # split date into year month day\n",
    "    data[\"Datetime\"] = pd.to_datetime(data[\"Datetime\"])\n",
    "    data[\"Year\"] = data[\"Datetime\"].apply(lambda x: x.year)\n",
    "    data[\"Month\"] = data[\"Datetime\"].apply(lambda x: x.month)\n",
    "    data[\"Day\"] = data[\"Datetime\"].apply(lambda x: x.day)\n",
    "    data[\"Hour\"] = data[\"Datetime\"].apply(lambda x: x.hour)\n",
    "    data[\"LinearDate\"] = (\n",
    "        pd.to_datetime(data[\"Datetime\"]) - pd.to_datetime(\"2022-06-01\")\n",
    "    ) / np.timedelta64(1, \"D\")\n",
    "\n",
    "    # for training, take relevant flights and calculate LF\n",
    "    if training:\n",
    "        mask = data[\"L Board Pax\"] > 10\n",
    "        data = data[mask].copy()\n",
    "        data[\"L Board Pax\"] = data[\"L Board Pax\"].astype(\"int\")\n",
    "        data[\"Load Factor\"] = data[\"L Board Pax\"] / data[\"Capacity\"]\n",
    "        # remove wrong and na values\n",
    "        data = data[\n",
    "            (data[\"Load Factor\"] < 1)\n",
    "            & (data[\"Load Factor\"] > 0)\n",
    "            & (data[\"Load Factor\"].notna())\n",
    "        ]\n",
    "    else:\n",
    "        data[\"L Board Pax\"] = np.nan\n",
    "        data[\"Load Factor\"] = np.nan\n",
    "\n",
    "    # change routing to Country name then to Country code\n",
    "    repl = (\n",
    "        data_airports[[\"ICAO\", \"Country\"]].set_index(\"ICAO\").T.to_dict(orient=\"records\")\n",
    "    )\n",
    "    data[\"Country\"] = data[\"Routing-FirstLeg\"].map(*repl)\n",
    "    repl_country = (\n",
    "        data_countries[[\"Name\", \"ISO-3166-1 alpha-2\"]]\n",
    "        .set_index(\"Name\")\n",
    "        .T.to_dict(orient=\"records\")\n",
    "    )\n",
    "    data[\"Country\"] = data[\"Country\"].map(*repl_country)\n",
    "\n",
    "    # holidays\n",
    "    data[\"HolidayJP\"] = 0\n",
    "    data[\"HolidayOrigin\"] = 0\n",
    "\n",
    "    dct_holiday = {\n",
    "        country_code: holidays.country_holidays(country_code)\n",
    "        for country_code in data[\"Country\"].unique()\n",
    "        if hasattr(holidays, country_code)\n",
    "    }\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        # domestic holiday\n",
    "        if row[\"Datetime\"] in dct_holiday[\"JP\"]:\n",
    "            data.loc[index, \"HolidayJP\"] = 1\n",
    "        # overseas holiday\n",
    "        if row[\"Country\"] in dct_holiday.keys():\n",
    "            if row[\"Datetime\"] in dct_holiday[row[\"Country\"]]:\n",
    "                data.loc[index, \"HolidayOrigin\"] = 1\n",
    "\n",
    "    # drop old columns\n",
    "    data.drop(\n",
    "        [\n",
    "            # \"L Board Pax\",\n",
    "            # \"Capacity\",\n",
    "            \"Routing-FirstLeg\",\n",
    "            # \"Datetime\",\n",
    "        ],\n",
    "        axis=\"columns\",\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # change types for categories\n",
    "    data[\"Service Type\"] = data[\"Service Type\"].astype(\"category\")\n",
    "    data[\"Traffic Type\"] = data[\"Traffic Type\"].astype(\"category\")\n",
    "    data[\"Direction\"] = data[\"Direction\"].astype(\"category\")\n",
    "    data[\"Country\"] = data[\"Country\"].astype(\"category\")\n",
    "\n",
    "    data[\"Month\"] = data[\"Month\"].astype(\"category\")\n",
    "    data[\"Day\"] = data[\"Day\"].astype(\"category\")\n",
    "    data[\"Hour\"] = data[\"Hour\"].astype(\"category\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine capacity for future flights\n",
    "# step 1: create a table of flight and capacity from actual data\n",
    "master_capacity = (\n",
    "    data_cleaning(data_actual)\n",
    "    .sort_values(by=\"Datetime\", ascending=False)[[\"Flight Designator\", \"Capacity\"]]\n",
    "    .groupby(\"Flight Designator\")\n",
    "    .tail(1)\n",
    ")\n",
    "# when no info, set mean\n",
    "master_capacity[\"Capacity\"].fillna(master_capacity[\"Capacity\"].mean(), inplace=True)\n",
    "\n",
    "# step 2 assign to future flight based on flight designator\n",
    "data_forecast_clean = (\n",
    "    data_cleaning(data_planned, training=False)\n",
    "    .drop(\"Capacity\", axis=1)\n",
    "    .join(master_capacity.set_index(\"Flight Designator\"), on=\"Flight Designator\")\n",
    ")\n",
    "# when no info, set mean\n",
    "data_forecast_clean[\"Capacity\"].fillna(\n",
    "    data_forecast_clean[\"Capacity\"].mean(), inplace=True\n",
    ")\n",
    "\n",
    "# prepare training data too\n",
    "data_actual_clean = data_cleaning(data_actual)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline creation and first fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline creation\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "model = XGBRegressor()\n",
    "# model = LGBMRegressor()\n",
    "regressor = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"regressor\", model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset for X, y and train, test\n",
    "X = data_actual_clean.drop(\n",
    "    [\n",
    "        \"Capacity\",\n",
    "        \"L Board Pax\",\n",
    "        \"Datetime\",\n",
    "        \"UniqueID\",\n",
    "        \"Flight Designator\",\n",
    "        \"Load Factor\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "y = data_actual_clean[\"Load Factor\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model\n",
    "regressor.fit(X_train, y_train)\n",
    "print(\"training score: %.3f\" % regressor.score(X_train, y_train))\n",
    "print(\"model score: %.3f\" % regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor[\"regressor\"].get_booster().feature_names = list(\n",
    "    regressor[\"preprocessor\"].get_feature_names_out()\n",
    ")\n",
    "xgb.plot_importance(regressor[\"regressor\"], ax=plt.gca(), max_num_features=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on future schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset for X, y and train, test\n",
    "X_forecast = data_forecast_clean.drop(\n",
    "    [\n",
    "        \"Capacity\",\n",
    "        \"L Board Pax\",\n",
    "        \"Datetime\",\n",
    "        \"UniqueID\",\n",
    "        \"Flight Designator\",\n",
    "        \"Load Factor\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "data_forecast_clean[\"Load Factor\"] = regressor.predict(X_forecast)\n",
    "data_forecast_clean[\"L Board Pax\"] = (\n",
    "    data_forecast_clean[\"Capacity\"] * data_forecast_clean[\"Load Factor\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare graphs for Pax count international departure\n",
    "\n",
    "# actual\n",
    "data_actual_result = data_actual_clean.set_index(\"Datetime\", drop=True)\n",
    "mask = (data_actual_result[\"Traffic Type\"] == \"INTERNATIONAL\") & (\n",
    "    data_actual_result[\"Direction\"] == \"departure\"\n",
    ")\n",
    "plot_actual_pax = data_actual_result[mask][\"L Board Pax\"].groupby(\n",
    "    pd.to_datetime(data_actual_result[mask].index).date\n",
    ")\n",
    "\n",
    "plot_actual_LF = data_actual_result[mask][\"Load Factor\"].groupby(\n",
    "    pd.to_datetime(data_actual_result[mask].index).date\n",
    ")\n",
    "\n",
    "# forecast\n",
    "data_forecast_result = data_forecast_clean.set_index(\"Datetime\", drop=True)\n",
    "mask = (data_forecast_result[\"Traffic Type\"] == \"INTERNATIONAL\") & (\n",
    "    data_forecast_result[\"Direction\"] == \"departure\"\n",
    ")\n",
    "plot_forecast_pax = data_forecast_result[mask][\"L Board Pax\"].groupby(\n",
    "    pd.to_datetime(data_forecast_result[mask].index).date\n",
    ")\n",
    "plot_forecast_LF = data_forecast_result[mask][\"Load Factor\"].groupby(\n",
    "    pd.to_datetime(data_forecast_result[mask].index).date\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    ncols=3,\n",
    "    figsize=(16, 6),\n",
    ")\n",
    "ax[0].plot(plot_forecast_pax.agg(\"count\"))\n",
    "ax[0].plot(plot_actual_pax.agg(\"count\"))\n",
    "ax[0].set(title=\"Flight number\")\n",
    "ax[1].plot(plot_forecast_pax.agg(\"sum\"))\n",
    "ax[1].plot(plot_actual_pax.agg(\"sum\"))\n",
    "ax[1].set(title=\"Pax number\")\n",
    "ax[2].plot(plot_forecast_LF.agg(\"mean\"))\n",
    "ax[2].plot(plot_actual_LF.agg(\"mean\"))\n",
    "ax[2].set(title=\"Load Factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"/home/antoine/projects/forecasting/output\") / \"forecast.csv\"\n",
    "data_forecast_result[[\"UniqueID\", \"L Board Pax\"]].reset_index().to_csv(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 | packaged by conda-forge | (main, Oct 25 2022, 06:24:40) [GCC 10.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5cde2381dd949eede0613f4452aac5627aca93dd18e02f051004af15b34586f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
