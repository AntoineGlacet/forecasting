{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_airports = pd.read_csv(\n",
    "    \"/home/yokhr/projects/forecasting/data/master_data_KIX_AODB/AODB_airport_master.csv\"\n",
    ")\n",
    "\n",
    "data_countries = pd.read_csv(\n",
    "    \"/home/yokhr/projects/forecasting/data/master_data_KIX_AODB/AODB_country_master.csv\"\n",
    ")\n",
    "\n",
    "all_files = list(\n",
    "    Path(\"/home/yokhr/projects/forecasting/data/KIX_AODB_data_planned\").glob(\"*.csv\")\n",
    ")\n",
    "data_planned = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "\n",
    "all_files = list(\n",
    "    Path(\"/home/yokhr/projects/forecasting/data/KIX_AODB_data\").glob(\"*.csv\")\n",
    ")\n",
    "data_actual = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "\n",
    "# filter out 17 January, it's today\n",
    "mask = pd.to_datetime(data_actual[\"[Arr] SIBT\"]).dt.floor(\"d\") != pd.to_datetime(\n",
    "    \"2023-1-26\"\n",
    ").floor(\"d\")\n",
    "data_actual = data_actual[mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## CSV read (for seat capacity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seat_cap = pd.read_csv(\n",
    "    \"/home/yokhr/projects/forecasting/data/seat_capacity_master.csv\"\n",
    ")\n",
    "\n",
    "data_seat_cap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning & augmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data_actual, training: bool = True):\n",
    "    # generate proper format\n",
    "    mask = (\n",
    "        (data_actual[\"[Dep] Flight Designator\"].notna())\n",
    "        & (~data_actual[\"[Arr] Status\"].isin([\"Not operating\", \"Cancelled\"]))\n",
    "        & (~data_actual[\"[Dep] Status\"].isin([\"Not operating\", \"Cancelled\"]))\n",
    "    )\n",
    "    data_dep = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"L Board Pax\": pd.to_numeric(\n",
    "                data_actual[mask][\"[Dep]  L Board Pax\"], errors=\"coerce\"\n",
    "            ).to_list(),\n",
    "            \"Routing-FirstLeg\": data_actual[mask][\"[Dep] Routing\"]\n",
    "            .apply(lambda x: x[-4:])\n",
    "            .to_list(),\n",
    "            \"Datetime\": pd.to_datetime(data_actual[mask][\"[Dep] SOBT\"]).to_list(),\n",
    "            \"Service Type\": data_actual[mask][\"[Dep] Service Type\"].to_list(),\n",
    "            \"Traffic Type\": data_actual[mask][\"[Dep] Traffic Type\"].to_list(),\n",
    "            \"UniqueID\": pd.to_datetime(data_actual[mask][\"[Dep] SOBT\"]).dt.strftime(\n",
    "                \"%Y/%m/%d\"\n",
    "            )\n",
    "            + \" \"\n",
    "            + data_actual[mask][\"[Dep] Flight Designator\"],\n",
    "            \"Capacity\": pd.to_numeric(\n",
    "                data_actual[mask][\"[Dep] Capacity\"], errors=\"coerce\"\n",
    "            ).to_list(),\n",
    "            \"Flight Designator\": data_actual[mask][\"[Dep] Flight Designator\"],\n",
    "            # yokhr to add AL+ACFT column\n",
    "            \"AL+ACFT\": data_actual[mask][\"[Dep] Flight Designator\"].str[:2]\n",
    "            + \"+\"\n",
    "            + data_actual[mask][\"Aircraft type\"],\n",
    "        }\n",
    "    )\n",
    "    data_dep[\"Direction\"] = \"departure\"\n",
    "\n",
    "    mask = data_actual[\"[Arr] Flight Designator\"].notna()\n",
    "    data_arr = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"L Board Pax\": pd.to_numeric(\n",
    "                data_actual[mask][\"[Arr]  L Board Pax\"], errors=\"coerce\"\n",
    "            ).to_list(),\n",
    "            \"Routing-FirstLeg\": data_actual[mask][\"[Arr] Routing\"]\n",
    "            .apply(lambda x: x[0:4])\n",
    "            .to_list(),\n",
    "            \"Datetime\": pd.to_datetime(data_actual[mask][\"[Arr] SIBT\"]).to_list(),\n",
    "            \"Service Type\": data_actual[mask][\"[Arr] Service Type\"].to_list(),\n",
    "            \"Traffic Type\": data_actual[mask][\"[Arr] Traffic Type\"].to_list(),\n",
    "            \"UniqueID\": pd.to_datetime(data_actual[mask][\"[Arr] SIBT\"]).dt.strftime(\n",
    "                \"%Y/%m/%d\"\n",
    "            )\n",
    "            + \" \"\n",
    "            + data_actual[mask][\"[Arr] Flight Designator\"],\n",
    "            \"Capacity\": pd.to_numeric(\n",
    "                data_actual[mask][\"[Arr] Capacity\"], errors=\"coerce\"\n",
    "            ).to_list(),\n",
    "            \"Flight Designator\": data_actual[mask][\"[Arr] Flight Designator\"],\n",
    "            # yokhr to add AL+ACFT column\n",
    "            \"AL+ACFT\": data_actual[mask][\"[Arr] Flight Designator\"].str[:2]\n",
    "            + \"+\"\n",
    "            + data_actual[mask][\"Aircraft type\"],\n",
    "        }\n",
    "    )\n",
    "    data_arr[\"Direction\"] = \"arrival\"\n",
    "\n",
    "    data_concat = pd.concat([data_dep, data_arr]).reset_index(drop=True)\n",
    "    data_concat.drop_duplicates(subset=[\"UniqueID\"], inplace=True)\n",
    "    data = data_concat.copy()\n",
    "\n",
    "    # select only useful columns\n",
    "    data = data[\n",
    "        [\n",
    "            \"Service Type\",  # string\n",
    "            \"Traffic Type\",  # string\n",
    "            \"Capacity\",  # to convert to int\n",
    "            \"L Board Pax\",  # int already\n",
    "            \"Direction\",  # string\n",
    "            \"Datetime\",  # date to convert to int for year/month/date/hour\n",
    "            \"Routing-FirstLeg\",  # string, should be country\n",
    "            \"UniqueID\",\n",
    "            \"Flight Designator\",\n",
    "            # yokhr to add AL+ACFT\n",
    "            \"AL+ACFT\",\n",
    "        ]\n",
    "    ].copy()\n",
    "\n",
    "    # filter out rows with irrelevant values\n",
    "    mask = data[\"Service Type\"].isin([\"C\", \"G\", \"J\"])\n",
    "    data = data[mask].copy()\n",
    "\n",
    "    # change capacity to numerical\n",
    "    data[\"Capacity\"] = pd.to_numeric(data[\"Capacity\"], errors=\"coerce\")\n",
    "    data[\"L Board Pax\"] = pd.to_numeric(data[\"L Board Pax\"], errors=\"coerce\")\n",
    "\n",
    "    # split date into year month day\n",
    "    data[\"Datetime\"] = pd.to_datetime(data[\"Datetime\"])\n",
    "    data[\"Year\"] = data[\"Datetime\"].apply(lambda x: x.year)\n",
    "    data[\"Month\"] = data[\"Datetime\"].apply(lambda x: x.month)\n",
    "    data[\"Day\"] = data[\"Datetime\"].apply(lambda x: x.day)\n",
    "    data[\"Weekday\"] = data[\"Datetime\"].apply(lambda x: x.weekday())\n",
    "    data[\"Hour\"] = data[\"Datetime\"].apply(lambda x: x.hour)\n",
    "    data[\"LinearDate\"] = (\n",
    "        pd.to_datetime(data[\"Datetime\"]) - pd.to_datetime(\"2022-06-01\")\n",
    "    ) / np.timedelta64(1, \"D\")\n",
    "\n",
    "    # for training, take relevant flights and calculate LF\n",
    "    if training:\n",
    "        mask = data[\"L Board Pax\"] > 10\n",
    "        data = data[mask].copy()\n",
    "        data[\"L Board Pax\"] = data[\"L Board Pax\"].astype(\"int\")\n",
    "        data[\"Load Factor\"] = data[\"L Board Pax\"] / data[\"Capacity\"]\n",
    "        # remove wrong and na values\n",
    "        data = data[\n",
    "            (data[\"Load Factor\"] < 1)\n",
    "            & (data[\"Load Factor\"] > 0)\n",
    "            & (data[\"Load Factor\"].notna())\n",
    "        ]\n",
    "    else:\n",
    "        data[\"L Board Pax\"] = np.nan\n",
    "        data[\"Load Factor\"] = np.nan\n",
    "\n",
    "    # change routing to Country name then to Country code\n",
    "    repl = (\n",
    "        data_airports[[\"ICAO\", \"Country\"]].set_index(\"ICAO\").T.to_dict(orient=\"records\")\n",
    "    )\n",
    "    data[\"Country\"] = data[\"Routing-FirstLeg\"].map(*repl)\n",
    "    repl_country = (\n",
    "        data_countries[[\"Name\", \"ISO-3166-1 alpha-2\"]]\n",
    "        .set_index(\"Name\")\n",
    "        .T.to_dict(orient=\"records\")\n",
    "    )\n",
    "    data[\"Country\"] = data[\"Country\"].map(*repl_country)\n",
    "\n",
    "    # holidays\n",
    "    data[\"HolidayJP\"] = 0\n",
    "    data[\"HolidayOrigin\"] = 0\n",
    "\n",
    "    dct_holiday = {\n",
    "        country_code: holidays.country_holidays(country_code)\n",
    "        for country_code in data[\"Country\"].unique()\n",
    "        if hasattr(holidays, country_code)\n",
    "    }\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        # domestic holiday\n",
    "        if row[\"Datetime\"] in dct_holiday[\"JP\"]:\n",
    "            data.loc[index, \"HolidayJP\"] = 1\n",
    "        # overseas holiday\n",
    "        if row[\"Country\"] in dct_holiday.keys():\n",
    "            if row[\"Datetime\"] in dct_holiday[row[\"Country\"]]:\n",
    "                data.loc[index, \"HolidayOrigin\"] = 1\n",
    "\n",
    "    # drop old columns\n",
    "    data.drop(\n",
    "        [\n",
    "            # \"L Board Pax\",\n",
    "            # \"Capacity\",\n",
    "            \"Routing-FirstLeg\",\n",
    "            # \"Datetime\",\n",
    "        ],\n",
    "        axis=\"columns\",\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # change types for categories\n",
    "    data[\"Service Type\"] = data[\"Service Type\"].astype(\"category\")\n",
    "    data[\"Traffic Type\"] = data[\"Traffic Type\"].astype(\"category\")\n",
    "    data[\"Direction\"] = data[\"Direction\"].astype(\"category\")\n",
    "    data[\"Country\"] = data[\"Country\"].astype(\"category\")\n",
    "\n",
    "    data[\"Month\"] = data[\"Month\"].astype(\"category\")\n",
    "    data[\"Day\"] = data[\"Day\"].astype(\"category\")\n",
    "    data[\"Weekday\"] = data[\"Weekday\"].astype(\"category\")\n",
    "    data[\"Hour\"] = data[\"Hour\"].astype(\"category\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yokhr to set Seat Capacity from AL + ACFT sheet by Asai-san"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seat_cap[\"AL+ACFT\"] = data_seat_cap[\"A/L\"] + \"+\" + data_seat_cap[\"Aircraft type\"]\n",
    "master_capacity1 = data_seat_cap[[\"AL+ACFT\", \"Capacity\"]]\n",
    "\n",
    "data_forecast_clean = (\n",
    "    data_cleaning(data_planned, training=False)\n",
    "    .drop(\"Capacity\", axis=1)\n",
    "    .join(master_capacity1.set_index(\"AL+ACFT\"), on=\"AL+ACFT\")\n",
    ")\n",
    "data_actual_clean = (\n",
    "    data_cleaning(data_actual)\n",
    "    .drop(\"Capacity\", axis=1)\n",
    "    .join(master_capacity1.set_index(\"AL+ACFT\"), on=\"AL+ACFT\")\n",
    ")\n",
    "# cap0 = data_forecast_clean[\"Capacity\"] == 0.0\n",
    "# data_forecast_clean[cap0][\"AL+ACFT\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline creation and first fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline creation\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "model = XGBRegressor()\n",
    "# model = LGBMRegressor()\n",
    "regressor = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"regressor\", model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset for X, y and train, test\n",
    "X = data_actual_clean.drop(\n",
    "    [\n",
    "        \"Capacity\",\n",
    "        \"L Board Pax\",\n",
    "        \"Datetime\",\n",
    "        \"UniqueID\",\n",
    "        \"Flight Designator\",\n",
    "        \"Load Factor\",\n",
    "        \"LinearDate\",\n",
    "        # yokhr to drop AL+ACFT as well\n",
    "        \"AL+ACFT\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "y = data_actual_clean[\"Load Factor\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model\n",
    "regressor.fit(X_train, y_train)\n",
    "print(\"training score: %.3f\" % regressor.score(X_train, y_train))\n",
    "print(\"model score: %.3f\" % regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor[\"regressor\"].get_booster().feature_names = list(\n",
    "    regressor[\"preprocessor\"].get_feature_names_out()\n",
    ")\n",
    "xgb.plot_importance(regressor[\"regressor\"], ax=plt.gca(), max_num_features=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on future schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset for X, y and train, test\n",
    "X_forecast = data_forecast_clean.drop(\n",
    "    [\n",
    "        \"Capacity\",\n",
    "        \"L Board Pax\",\n",
    "        \"Datetime\",\n",
    "        \"UniqueID\",\n",
    "        \"Flight Designator\",\n",
    "        \"Load Factor\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "data_forecast_clean[\"Load Factor ML\"] = regressor.predict(X_forecast)\n",
    "data_forecast_clean[\"L Board Pax ML\"] = (\n",
    "    data_forecast_clean[\"Capacity\"] * data_forecast_clean[\"Load Factor ML\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekday average over last 2 weeks method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Asai_estimator:\n",
    "    \"\"\"\n",
    "    An estimator to be trained on last 2 weeks of international flights.\n",
    "    Estimate future flights LF based on the weekday average over last 2 weeks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        build a DataFrame of LF for international flights\n",
    "        by direction, by weekday, takes the average of last 2 weeks of available data\n",
    "        \"\"\"\n",
    "        X_train[\"Datetime\"] = pd.to_datetime(\n",
    "            X_train[\"Year\"].astype(str)\n",
    "            + \"-\"\n",
    "            + X_train[\"Month\"].astype(str)\n",
    "            + \"-\"\n",
    "            + X_train[\"Day\"].astype(str)\n",
    "        )\n",
    "        X_train[\"LF\"] = y_train\n",
    "        train = X_train\n",
    "\n",
    "        # select last 2 weeks of international flights\n",
    "        mask_2weeks = (\n",
    "            train[\"Datetime\"] < train[\"Datetime\"].max() - pd.Timedelta(days=1)\n",
    "        ) & (train[\"Datetime\"] > train[\"Datetime\"].max() - pd.Timedelta(days=16))\n",
    "        mask_int = train[\"Traffic Type\"] == \"INTERNATIONAL\"\n",
    "\n",
    "        self.LF_RefTable = train[mask_2weeks & mask_int].copy()\n",
    "\n",
    "        # group by weekday and direction and take the average\n",
    "        self.LF_RefTable = self.LF_RefTable.groupby(by=[\"Weekday\", \"Direction\"])[\n",
    "            [\"LF\"]\n",
    "        ].agg(\"mean\")\n",
    "\n",
    "    def predict(self, X_forecast):\n",
    "        result = X_forecast.join(self.LF_RefTable, on=[\"Weekday\", \"Direction\"])\n",
    "        self.prediction = result[\"LF\"]\n",
    "        return self.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and put values in dataframe\n",
    "estimator = Asai_estimator()\n",
    "estimator.train(X_train, y_train)\n",
    "\n",
    "data_forecast_clean[\"Load Factor Asai\"] = estimator.predict(X_forecast)\n",
    "data_forecast_clean[\"L Board Pax Asai\"] = (\n",
    "    data_forecast_clean[\"Capacity\"] * data_forecast_clean[\"Load Factor Asai\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick plot for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare graphs for Pax count international departure\n",
    "\n",
    "# actual\n",
    "data_actual_result = data_actual_clean.set_index(\"Datetime\", drop=True)\n",
    "mask = (data_actual_result[\"Traffic Type\"] == \"INTERNATIONAL\") & (\n",
    "    data_actual_result[\"Direction\"] == \"departure\"\n",
    ")\n",
    "plot_actual_pax = data_actual_result[mask][\"L Board Pax\"].groupby(\n",
    "    pd.to_datetime(data_actual_result[mask].index).date\n",
    ")\n",
    "\n",
    "plot_actual_LF = data_actual_result[mask][\"Load Factor\"].groupby(\n",
    "    pd.to_datetime(data_actual_result[mask].index).date\n",
    ")\n",
    "\n",
    "# forecast\n",
    "data_forecast_result = data_forecast_clean.set_index(\"Datetime\", drop=True)\n",
    "\n",
    "mask = (data_forecast_result[\"Traffic Type\"] == \"INTERNATIONAL\") & (\n",
    "    data_forecast_result[\"Direction\"] == \"departure\"\n",
    ")\n",
    "\n",
    "plot_forecast_pax_ML = data_forecast_result[mask][\"L Board Pax ML\"].groupby(\n",
    "    pd.to_datetime(data_forecast_result[mask].index).date\n",
    ")\n",
    "plot_forecast_LF_ML = data_forecast_result[mask][\"Load Factor ML\"].groupby(\n",
    "    pd.to_datetime(data_forecast_result[mask].index).date\n",
    ")\n",
    "\n",
    "plot_forecast_pax_Asai = data_forecast_result[mask][\"L Board Pax Asai\"].groupby(\n",
    "    pd.to_datetime(data_forecast_result[mask].index).date\n",
    ")\n",
    "plot_forecast_LF_Asai = data_forecast_result[mask][\"Load Factor Asai\"].groupby(\n",
    "    pd.to_datetime(data_forecast_result[mask].index).date\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    ncols=3,\n",
    "    figsize=(16, 6),\n",
    ")\n",
    "\n",
    "ax[0].plot(plot_actual_pax.agg(\"count\"), label=\"actual\")\n",
    "ax[0].plot(plot_forecast_pax_ML.agg(\"count\"), label=\"planned\")\n",
    "ax[0].set(title=\"Flight number\")\n",
    "\n",
    "ax[1].plot(plot_actual_pax.agg(\"sum\"))\n",
    "ax[1].plot(plot_forecast_pax_ML.agg(\"sum\"), label=\"ML\")\n",
    "ax[1].plot(plot_forecast_pax_Asai.agg(\"sum\"), label=\"Asai\")\n",
    "ax[1].set(title=\"Pax number\")\n",
    "\n",
    "ax[2].plot(plot_actual_LF.agg(\"mean\"))\n",
    "ax[2].plot(plot_forecast_LF_ML.agg(\"mean\"), label=\"ML\")\n",
    "ax[2].plot(plot_forecast_LF_Asai.agg(\"mean\"), label=\"Asai\")\n",
    "ax[2].set(title=\"Load Factor\")\n",
    "\n",
    "myFmt = mdates.DateFormatter(\"%b '%y\")\n",
    "for ax in ax:\n",
    "    ax.set_xticklabels(ax.get_xticks(), rotation=45, **{\"horizontalalignment\": \"right\"})\n",
    "    ax.xaxis.set_major_formatter(myFmt)\n",
    "    ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"uniqueID\": [\n",
    "            y for x in data_forecast_result[\"UniqueID\"].to_list() for y in [x, x]\n",
    "        ],\n",
    "        \"Datetime\": [y for x in data_forecast_result.index.to_list() for y in [x, x]],\n",
    "        \"Model\": [\"ML\", \"Asai\"] * len(data_forecast_result[\"UniqueID\"]),\n",
    "        \"Load Factor\": [\n",
    "            x\n",
    "            for sub in zip(\n",
    "                data_forecast_result[\"Load Factor ML\"].to_list(),\n",
    "                data_forecast_result[\"Load Factor Asai\"].to_list(),\n",
    "            )\n",
    "            for x in sub\n",
    "        ],\n",
    "        \"Pax\": [\n",
    "            x\n",
    "            for sub in zip(\n",
    "                data_forecast_result[\"L Board Pax ML\"].to_list(),\n",
    "                data_forecast_result[\"L Board Pax Asai\"].to_list(),\n",
    "            )\n",
    "            for x in sub\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"/home/antoine/projects/forecasting/output\") / \"forecast_new.csv\"\n",
    "result.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 15 Feb~\n",
    "test = pd.read_csv(\"/home/antoine/projects/forecasting/output/forecast_new.csv\")\n",
    "mask = pd.to_datetime(test[\"Datetime\"]) > pd.to_datetime(\"2023-02-15\")\n",
    "out_path = (\n",
    "    Path(\"/home/antoine/projects/forecasting/output\") / \"forecast_new_after1502.csv\"\n",
    ")\n",
    "test[mask].to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/home/antoine/projects/forecasting/output/forecast_jan.csv\")\n",
    "mask = pd.to_datetime(test[\"Datetime\"]).dt.month == 1\n",
    "out_path = Path(\"/home/antoine/projects/forecasting/output\") / \"forecast_jan_edit.csv\"\n",
    "test[mask].to_csv(out_path)\n",
    "\n",
    "test = pd.read_csv(\"/home/antoine/projects/forecasting/output/forecast_feb.csv\")\n",
    "mask = pd.to_datetime(test[\"Datetime\"]).dt.month == 2\n",
    "out_path = Path(\"/home/antoine/projects/forecasting/output\") / \"forecast_feb_edit.csv\"\n",
    "test[mask].to_csv(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e4b644f48aab624ad8f139f0a8f696b4293b6e17dcfe99aae48dae46a418002"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
